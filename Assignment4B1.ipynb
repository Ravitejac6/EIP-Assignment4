{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment4B1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ravitejac6/EIP-Assignment4/blob/master/Assignment4B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4ZykrQIQCUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import os\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF1RyWNeSa6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training parameters\n",
        "batch_size = 128  # orig paper trained all networks with batch_size=128\n",
        "epochs = 50\n",
        "data_augmentation = True\n",
        "num_classes = 10\n",
        "\n",
        "# Subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuHGiR6RShGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 3\n",
        "\n",
        "# Model version\n",
        "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
        "version = 1\n",
        "\n",
        "# Computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXG2wCB7SuBF",
        "colab_type": "code",
        "outputId": "c09ca367-04f5-48ec-b948-44ad42875173",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "print(model_type)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet20v1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRNlJhTeSydp",
        "colab_type": "code",
        "outputId": "00746c37-029b-4057-b34e-2b8a1a48ad8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "print(input_shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkfcoIIRS3t7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbahf-zoS8Sm",
        "colab_type": "code",
        "outputId": "d8bfdd1a-cbf9-4aa4-ef50-d2656348d110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bliy7uQCS_TV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztYG7WbcTD38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN8XDVqBTLA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfKWSTr8TPnn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIEvlYf2TWlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v2(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
        "    bottleneck layer\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
        "    # Start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNUrkGIoTeyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2xOYw1XoB_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_bNwBZuvxHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),  #lr_schedule(100) #lr=lr_schedule(50)\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njPe_s3baL6U",
        "colab_type": "code",
        "outputId": "0f5aeb67-2994-494e-e6c8-a3fde378ad52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 32, 32, 16)   448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 32, 16)   64          conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 16)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 32, 32, 16)   2320        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 32, 32, 16)   64          conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 32, 32, 16)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 32, 32, 16)   2320        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 32, 32, 16)   64          conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 32, 32, 16)   0           activation_20[0][0]              \n",
            "                                                                 batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 32, 32, 16)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 32, 32, 16)   2320        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 32, 32, 16)   64          conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 32, 32, 16)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 32, 32, 16)   2320        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 32, 32, 16)   64          conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 32, 32, 16)   0           activation_22[0][0]              \n",
            "                                                                 batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 32, 32, 16)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 32, 32, 16)   2320        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 32, 32, 16)   64          conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 32, 32, 16)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 32, 32, 16)   2320        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 32, 32, 16)   64          conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 32, 32, 16)   0           activation_24[0][0]              \n",
            "                                                                 batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 32, 32, 16)   0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 16, 16, 32)   4640        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 32)   128         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 32)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 16, 16, 32)   9248        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 16, 16, 32)   544         activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 32)   128         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 16, 16, 32)   0           conv2d_31[0][0]                  \n",
            "                                                                 batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 32)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 16, 16, 32)   9248        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 16, 16, 32)   128         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 16, 16, 32)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 16, 16, 32)   9248        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 16, 16, 32)   128         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 16, 16, 32)   0           activation_28[0][0]              \n",
            "                                                                 batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 16, 16, 32)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 16, 16, 32)   9248        activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 16, 16, 32)   128         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 16, 16, 32)   0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 16, 16, 32)   9248        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 16, 16, 32)   128         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 16, 16, 32)   0           activation_30[0][0]              \n",
            "                                                                 batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 16, 16, 32)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 64)     18496       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 64)     256         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 64)     0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 8, 64)     36928       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 8, 8, 64)     2112        activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 64)     256         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 8, 8, 64)     0           conv2d_38[0][0]                  \n",
            "                                                                 batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 8, 64)     0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 8, 8, 64)     36928       activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 64)     256         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 64)     0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 8, 8, 64)     36928       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 64)     256         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 8, 8, 64)     0           activation_34[0][0]              \n",
            "                                                                 batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 64)     0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 8, 8, 64)     36928       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 64)     256         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 64)     0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 8, 8, 64)     36928       activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 8, 8, 64)     256         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 8, 8, 64)     0           activation_36[0][0]              \n",
            "                                                                 batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 8, 64)     0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 1, 1, 64)     0           activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 64)           0           average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           650         flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 274,442\n",
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUfOMEAVaMxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "#lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer] #, lr_scheduler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7eivnrDwbtt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
        "    def eraser(input_img):\n",
        "        img_h, img_w, img_c = input_img.shape\n",
        "        p_1 = np.random.rand()\n",
        "\n",
        "        if p_1 > p:\n",
        "            return input_img\n",
        "\n",
        "        while True:\n",
        "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "            r = np.random.uniform(r_1, r_2)\n",
        "            w = int(np.sqrt(s / r))\n",
        "            h = int(np.sqrt(s * r))\n",
        "            left = np.random.randint(0, img_w)\n",
        "            top = np.random.randint(0, img_h)\n",
        "\n",
        "            if left + w <= img_w and top + h <= img_h:\n",
        "                break\n",
        "\n",
        "        if pixel_level:\n",
        "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "        else:\n",
        "            c = np.random.uniform(v_l, v_h)\n",
        "\n",
        "        input_img[top:top + h, left:left + w, :] = c\n",
        "\n",
        "        return input_img\n",
        "\n",
        "    return eraser"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdwG-0ddwpkW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pixel_level = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXsvKsnwvkOo",
        "colab_type": "code",
        "outputId": "4741abfe-d895-4aef-bfe7-4e7caddebb33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Run training, with or without data augmentation.\n",
        "#from random_eraser import get_random_eraser\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True\n",
        "              ) #callbacks=callbacks\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        preprocessing_function=get_random_eraser(v_l=0, v_h=1, pixel_level=pixel_level))\n",
        "    # Compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model_info =  model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, workers=4,\n",
        "                        callbacks=callbacks) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/50\n",
            "391/391 [==============================] - 62s 159ms/step - loss: 1.7310 - acc: 0.4267 - val_loss: 1.4567 - val_acc: 0.5232\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.52320, saving model to /content/saved_models/cifar10_ResNet20v1_model.001.h5\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 56s 143ms/step - loss: 1.3796 - acc: 0.5587 - val_loss: 1.4779 - val_acc: 0.5401\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.52320 to 0.54010, saving model to /content/saved_models/cifar10_ResNet20v1_model.002.h5\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 1.2190 - acc: 0.6158 - val_loss: 1.2767 - val_acc: 0.6226\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.54010 to 0.62260, saving model to /content/saved_models/cifar10_ResNet20v1_model.003.h5\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 1.1057 - acc: 0.6600 - val_loss: 1.5266 - val_acc: 0.5551\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.62260\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 55s 139ms/step - loss: 1.0251 - acc: 0.6896 - val_loss: 1.1941 - val_acc: 0.6497\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.62260 to 0.64970, saving model to /content/saved_models/cifar10_ResNet20v1_model.005.h5\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 52s 132ms/step - loss: 0.9633 - acc: 0.7115 - val_loss: 0.9199 - val_acc: 0.7341\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.64970 to 0.73410, saving model to /content/saved_models/cifar10_ResNet20v1_model.006.h5\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 51s 130ms/step - loss: 0.9237 - acc: 0.7263 - val_loss: 0.9614 - val_acc: 0.7187\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.73410\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 51s 131ms/step - loss: 0.8807 - acc: 0.7402 - val_loss: 1.0509 - val_acc: 0.6888\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.73410\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 50s 128ms/step - loss: 0.8473 - acc: 0.7553 - val_loss: 1.0495 - val_acc: 0.7150\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.73410\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 50s 128ms/step - loss: 0.8168 - acc: 0.7650 - val_loss: 0.8576 - val_acc: 0.7574\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.73410 to 0.75740, saving model to /content/saved_models/cifar10_ResNet20v1_model.010.h5\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 50s 128ms/step - loss: 0.7956 - acc: 0.7717 - val_loss: 0.8685 - val_acc: 0.7577\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.75740 to 0.75770, saving model to /content/saved_models/cifar10_ResNet20v1_model.011.h5\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 50s 128ms/step - loss: 0.7693 - acc: 0.7821 - val_loss: 0.8086 - val_acc: 0.7744\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.75770 to 0.77440, saving model to /content/saved_models/cifar10_ResNet20v1_model.012.h5\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 50s 128ms/step - loss: 0.7462 - acc: 0.7910 - val_loss: 0.8330 - val_acc: 0.7665\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.77440\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 50s 128ms/step - loss: 0.7318 - acc: 0.7951 - val_loss: 1.1238 - val_acc: 0.6989\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.77440\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 50s 127ms/step - loss: 0.7168 - acc: 0.8015 - val_loss: 1.0347 - val_acc: 0.7141\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.77440\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 50s 127ms/step - loss: 0.7019 - acc: 0.8062 - val_loss: 0.8126 - val_acc: 0.7787\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.77440 to 0.77870, saving model to /content/saved_models/cifar10_ResNet20v1_model.016.h5\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 49s 126ms/step - loss: 0.6903 - acc: 0.8118 - val_loss: 0.7479 - val_acc: 0.7974\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.77870 to 0.79740, saving model to /content/saved_models/cifar10_ResNet20v1_model.017.h5\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 49s 126ms/step - loss: 0.6763 - acc: 0.8159 - val_loss: 0.7862 - val_acc: 0.7975\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.79740 to 0.79750, saving model to /content/saved_models/cifar10_ResNet20v1_model.018.h5\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - 49s 126ms/step - loss: 0.6659 - acc: 0.8189 - val_loss: 0.8366 - val_acc: 0.7652\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.79750\n",
            "Epoch 20/50\n",
            "391/391 [==============================] - 50s 127ms/step - loss: 0.6549 - acc: 0.8239 - val_loss: 0.7340 - val_acc: 0.8058\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.79750 to 0.80580, saving model to /content/saved_models/cifar10_ResNet20v1_model.020.h5\n",
            "Epoch 21/50\n",
            "391/391 [==============================] - 49s 126ms/step - loss: 0.6430 - acc: 0.8278 - val_loss: 0.7859 - val_acc: 0.7857\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80580\n",
            "Epoch 22/50\n",
            "391/391 [==============================] - 50s 127ms/step - loss: 0.6297 - acc: 0.8315 - val_loss: 0.6430 - val_acc: 0.8395\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.80580 to 0.83950, saving model to /content/saved_models/cifar10_ResNet20v1_model.022.h5\n",
            "Epoch 23/50\n",
            "391/391 [==============================] - 49s 126ms/step - loss: 0.6325 - acc: 0.8297 - val_loss: 0.7718 - val_acc: 0.7947\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.83950\n",
            "Epoch 24/50\n",
            "391/391 [==============================] - 49s 126ms/step - loss: 0.6172 - acc: 0.8363 - val_loss: 0.7207 - val_acc: 0.8126\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.83950\n",
            "Epoch 25/50\n",
            "391/391 [==============================] - 49s 126ms/step - loss: 0.6100 - acc: 0.8386 - val_loss: 0.8211 - val_acc: 0.7855\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.83950\n",
            "Epoch 26/50\n",
            "391/391 [==============================] - 49s 126ms/step - loss: 0.5982 - acc: 0.8440 - val_loss: 0.7116 - val_acc: 0.8164\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.83950\n",
            "Epoch 27/50\n",
            "391/391 [==============================] - 50s 127ms/step - loss: 0.5951 - acc: 0.8456 - val_loss: 0.8963 - val_acc: 0.7728\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.83950\n",
            "Epoch 28/50\n",
            "391/391 [==============================] - 49s 127ms/step - loss: 0.5240 - acc: 0.8686 - val_loss: 0.5601 - val_acc: 0.8620\n",
            "\n",
            "Epoch 00028: val_acc improved from 0.83950 to 0.86200, saving model to /content/saved_models/cifar10_ResNet20v1_model.028.h5\n",
            "Epoch 29/50\n",
            "391/391 [==============================] - 49s 126ms/step - loss: 0.5032 - acc: 0.8759 - val_loss: 0.5675 - val_acc: 0.8634\n",
            "\n",
            "Epoch 00029: val_acc improved from 0.86200 to 0.86340, saving model to /content/saved_models/cifar10_ResNet20v1_model.029.h5\n",
            "Epoch 30/50\n",
            "391/391 [==============================] - 50s 127ms/step - loss: 0.4886 - acc: 0.8795 - val_loss: 0.5930 - val_acc: 0.8546\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.86340\n",
            "Epoch 31/50\n",
            "391/391 [==============================] - 49s 127ms/step - loss: 0.4826 - acc: 0.8802 - val_loss: 0.5538 - val_acc: 0.8643\n",
            "\n",
            "Epoch 00031: val_acc improved from 0.86340 to 0.86430, saving model to /content/saved_models/cifar10_ResNet20v1_model.031.h5\n",
            "Epoch 32/50\n",
            "391/391 [==============================] - 50s 129ms/step - loss: 0.4746 - acc: 0.8826 - val_loss: 0.5366 - val_acc: 0.8689\n",
            "\n",
            "Epoch 00032: val_acc improved from 0.86430 to 0.86890, saving model to /content/saved_models/cifar10_ResNet20v1_model.032.h5\n",
            "Epoch 33/50\n",
            "391/391 [==============================] - 50s 128ms/step - loss: 0.4641 - acc: 0.8863 - val_loss: 0.6149 - val_acc: 0.8532\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.86890\n",
            "Epoch 34/50\n",
            "391/391 [==============================] - 50s 127ms/step - loss: 0.4573 - acc: 0.8890 - val_loss: 0.5535 - val_acc: 0.8643\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.86890\n",
            "Epoch 35/50\n",
            "391/391 [==============================] - 50s 127ms/step - loss: 0.4536 - acc: 0.8895 - val_loss: 0.5640 - val_acc: 0.8677\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.86890\n",
            "Epoch 36/50\n",
            "391/391 [==============================] - 50s 127ms/step - loss: 0.4545 - acc: 0.8893 - val_loss: 0.5744 - val_acc: 0.8607\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.86890\n",
            "Epoch 37/50\n",
            "391/391 [==============================] - 50s 127ms/step - loss: 0.4508 - acc: 0.8901 - val_loss: 0.5176 - val_acc: 0.8720\n",
            "\n",
            "Epoch 00037: val_acc improved from 0.86890 to 0.87200, saving model to /content/saved_models/cifar10_ResNet20v1_model.037.h5\n",
            "Epoch 38/50\n",
            "391/391 [==============================] - 50s 127ms/step - loss: 0.4462 - acc: 0.8897 - val_loss: 0.5776 - val_acc: 0.8577\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.87200\n",
            "Epoch 39/50\n",
            "391/391 [==============================] - 50s 128ms/step - loss: 0.4374 - acc: 0.8913 - val_loss: 0.6985 - val_acc: 0.8260\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.87200\n",
            "Epoch 40/50\n",
            "391/391 [==============================] - 50s 128ms/step - loss: 0.4309 - acc: 0.8956 - val_loss: 0.5949 - val_acc: 0.8529\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.87200\n",
            "Epoch 41/50\n",
            "391/391 [==============================] - 50s 127ms/step - loss: 0.4324 - acc: 0.8942 - val_loss: 0.5329 - val_acc: 0.8676\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.87200\n",
            "Epoch 42/50\n",
            "391/391 [==============================] - 50s 127ms/step - loss: 0.4325 - acc: 0.8941 - val_loss: 0.5618 - val_acc: 0.8624\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.87200\n",
            "Epoch 43/50\n",
            "391/391 [==============================] - 49s 126ms/step - loss: 0.3986 - acc: 0.9046 - val_loss: 0.4872 - val_acc: 0.8827\n",
            "\n",
            "Epoch 00043: val_acc improved from 0.87200 to 0.88270, saving model to /content/saved_models/cifar10_ResNet20v1_model.043.h5\n",
            "Epoch 44/50\n",
            "391/391 [==============================] - 49s 126ms/step - loss: 0.3881 - acc: 0.9084 - val_loss: 0.4773 - val_acc: 0.8841\n",
            "\n",
            "Epoch 00044: val_acc improved from 0.88270 to 0.88410, saving model to /content/saved_models/cifar10_ResNet20v1_model.044.h5\n",
            "Epoch 45/50\n",
            "391/391 [==============================] - 49s 126ms/step - loss: 0.3840 - acc: 0.9113 - val_loss: 0.4827 - val_acc: 0.8839\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.88410\n",
            "Epoch 46/50\n",
            "391/391 [==============================] - 49s 126ms/step - loss: 0.3782 - acc: 0.9119 - val_loss: 0.4918 - val_acc: 0.8816\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.88410\n",
            "Epoch 47/50\n",
            "391/391 [==============================] - 50s 127ms/step - loss: 0.3811 - acc: 0.9117 - val_loss: 0.4779 - val_acc: 0.8854\n",
            "\n",
            "Epoch 00047: val_acc improved from 0.88410 to 0.88540, saving model to /content/saved_models/cifar10_ResNet20v1_model.047.h5\n",
            "Epoch 48/50\n",
            "391/391 [==============================] - 49s 124ms/step - loss: 0.3739 - acc: 0.9136 - val_loss: 0.5009 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.88540\n",
            "Epoch 49/50\n",
            "391/391 [==============================] - 49s 125ms/step - loss: 0.3704 - acc: 0.9146 - val_loss: 0.4829 - val_acc: 0.8840\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.88540\n",
            "Epoch 50/50\n",
            "391/391 [==============================] - 49s 126ms/step - loss: 0.3637 - acc: 0.9161 - val_loss: 0.4738 - val_acc: 0.8858\n",
            "\n",
            "Epoch 00050: val_acc improved from 0.88540 to 0.88580, saving model to /content/saved_models/cifar10_ResNet20v1_model.050.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64C9xDvix0bz",
        "colab_type": "code",
        "outputId": "a7994501-a922-4ced-bdd2-9bb3f28338d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3s 301us/step\n",
            "Test loss: 0.47376957993507385\n",
            "Test accuracy: 0.8858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkJrRQpRx41f",
        "colab_type": "code",
        "outputId": "6c2e91b7-1550-4de4-b22c-8da89b64a218",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "plot_model_history(model_info)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFNCAYAAABSRs15AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEmSpJr4f5Edjuw5sPvnAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}